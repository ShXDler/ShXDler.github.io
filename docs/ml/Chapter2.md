# 2.1 经验误差与过拟合

误差：实际预测输出和真实输出间的差异——训练误差（经验误差）、泛化误差

对过拟合、欠拟合问题，进行模型选择。

# 2.2 评估方法

建立测试集，与真实分布i.i.d，同时与训练集互斥。

## 2.2.1 留出法（hold-out）

将数据集$D$划分为两个互斥的训练集$S$和测试集$T$，使用$S$上训练出的模型用$T$评估模型。

首先，训练集和测试集的划分要保证数据分布i.i.d，如使用分层抽样保留类别比例。另外，在给定训练集测试集大小比例后，可以采用若干次随机划分的重复实验，计算结果的平均值。训练集比例常在2/3到4/5之间，测试集一般不少于30条观测。

## 2.2.2 交叉验证法（cross validation）

将原始数据集划分成$k$个大小相似的数据集重复$p$次，进行$p$次$k$折交叉验证。$k$等于样本量$m$时的特例又叫留一法，它的评价结果相对准确，但是计算开销很大。

## 2.2.3 自助法（bootstrap）

由于训练集要比整体数据集小，可能会产生一定的估计偏差，可以使用自助法进行实验估计。自助法以自助采样法（bootstrap sampling，亦称可重复采样或有放回采样）为基础，在给定包含$m$个样本的数据集$D$，每次随机从$D$中挑选一个样本，复制进$D'$中再放回，重复$m$次即可。在采样过程中，$m$次采样中某一样本没有被采到的概率为$\lim_{m\rightarrow\infty}(1-\frac1m)^m=\frac1e\approx0.368$，所以可以用$D\setminus D'$作为测试集，这种测试结果也称“包外估计”（out-of-bag estimate）。

自助法在数据集较小、难以划分集合的时候很有用，同时还能产生多个不同的训练集，有利于集成学习。而自助法改变了初始数据集的分布，会引入估计偏差，在数据量足够时，留出法和交叉验证法更常用。

## 2.2.4 调参与最终模型

用训练集和验证集对参数设定范围和变化步长来调参，在模型选择完后，使用所有$m$个样本训练最终模型，并在测试集上估计模型的泛化能力。

# 2.3 性能度量

回归分析常用均方误差（MSE）：

$$E(f;D)=\frac1m\sum^m_{i=1}(f(x_i)-y_i)^2$$

